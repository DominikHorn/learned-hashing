{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5a34b1-02d7-4c2f-b198-d3032454a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17911b2b-b1d6-4c80-b4cb-faa82b8e2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "  'font.size': 8,\n",
    "  'text.usetex': True,\n",
    "  'text.latex.preamble': r'\\usepackage{amsmath}',\n",
    "  'pgf.texsystem': \"pdflatex\",\n",
    "  'pgf.preamble': r'\\usepackage{amsfonts}',\n",
    "  #\"font.family\": \"serif\",\n",
    "  #\"pgf.rcfonts\": False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4decb05a-c983-443b-a14c-8294eb581161",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_width=6\n",
    "fig_height=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523ee30e-75db-462e-9229-f01dcabeadfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_i = 0\n",
    "colors = {}\n",
    "def get_color(fun):\n",
    "    global color_i\n",
    "    global colors\n",
    "    \n",
    "    key = fun.lower()\n",
    "    if key not in colors:\n",
    "        options = list(mcolors.TABLEAU_COLORS) + list(mcolors.BASE_COLORS)[0:-1]\n",
    "        colors[key] = options[color_i % len(options)]\n",
    "        color_i += 1\n",
    "    return colors[key]\n",
    "\n",
    "def reset_colors():\n",
    "    global color_i\n",
    "    global colors\n",
    "    color_i = 0\n",
    "    colors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af950fe-9266-4004-be50-336ca799b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = f\"../results.json\"\n",
    "with open (results_file) as file:\n",
    "    data = json.load(file)\n",
    "    df = pd.json_normalize(data, \"benchmarks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066dc5f8-1831-424a-9ac9-dffd0c1e9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marker(f):\n",
    "    if f.startswith(\"cht\"):\n",
    "        return \".\"\n",
    "    if f.startswith(\"pgm\"):\n",
    "        return \"1\"\n",
    "    if f.startswith(\"radix_spline\"):\n",
    "        return \"v\"\n",
    "    if f.startswith(\"trie_spline\"):\n",
    "        return \"^\"\n",
    "    if f.startswith(\"rmi\"):\n",
    "        return \"x\"\n",
    "    \n",
    "    return \"*\"\n",
    "\n",
    "def dataset_name(d):\n",
    "    return {'books': \"amazon\", \n",
    "            'fb': \"facebook\", \n",
    "            'gap_10': \"gapped 10%\",\n",
    "            'osm': \"open street map\",\n",
    "            'seq': \"sequential\",\n",
    "            'normal': \"normal\",\n",
    "            'uniform': \"uniform\",\n",
    "            'wiki': \"wikipedia\"}[d]\n",
    "\n",
    "def dataset_order(d):\n",
    "    return {n: i for i, n in enumerate([\n",
    "            'sequential', \n",
    "            'gapped 10%',\n",
    "            'normal',\n",
    "            'uniform',\n",
    "            'amazon',\n",
    "            'wikipedia',\n",
    "            'facebook',\n",
    "            'open street map'\n",
    "        ])}[d]\n",
    "\n",
    "def function_name(f):\n",
    "    return {\n",
    "        'DoNothing64': \"DoNothing\",\n",
    "        'cht_64_128': \"CHT ($\\epsilon=128$)\",\n",
    "        'cht_64_16': \"CHT ($\\epsilon=16$)\",\n",
    "        'cht_64_4': \"CHT ($\\epsilon=4$)\",\n",
    "        'pgm_hash_eps128_epsrec128': \"PGM ($\\epsilon=128$)\",\n",
    "        'pgm_hash_eps16_epsrec16': \"PGM ($\\epsilon=16$)\",\n",
    "        'pgm_hash_eps4_epsrec4': \"PGM ($\\epsilon=4$)\",\n",
    "        'radix_spline_err128_rbits18': \"RadixSpline ($\\epsilon=128, r=18$)\",\n",
    "        'radix_spline_err16_rbits18': \"RadixSpline ($\\epsilon=16, r=18$)\",\n",
    "        'radix_spline_err4_rbits18': \"RadixSpline ($\\epsilon=4, r=18$)\",\n",
    "        'rmi_hash_100': \"RMI ($\\leq 10^2$)\",\n",
    "        'rmi_hash_10000': \"RMI ($\\leq 10^4$)\",\n",
    "        'rmi_hash_1000000': \"RMI ($\\leq 10^6$)\",\n",
    "        'trie_spline_err128': \"PLEX ($\\epsilon=128$)\",\n",
    "        'trie_spline_err16': \"PLEX ($\\epsilon=16$)\",\n",
    "        'trie_spline_err4': \"PLEX ($\\epsilon=4$)\"\n",
    "    }[f]\n",
    "\n",
    "def do_order(f):\n",
    "    return {n: i for i, n in enumerate([\n",
    "        'rmi_hash_100',\n",
    "        'rmi_hash_10000',\n",
    "        'rmi_hash_1000000',\n",
    "        'pgm_hash_eps128_epsrec128',\n",
    "        'pgm_hash_eps16_epsrec16',\n",
    "        'pgm_hash_eps4_epsrec4',\n",
    "        'radix_spline_err128_rbits18',\n",
    "        'radix_spline_err16_rbits18',\n",
    "        'radix_spline_err4_rbits18',\n",
    "        'trie_spline_err128',\n",
    "        'trie_spline_err16',\n",
    "        'trie_spline_err4',\n",
    "        'cht_64_128',\n",
    "        'cht_64_16',\n",
    "        'cht_64_4',\n",
    "    ])}[f]\n",
    "\n",
    "def probing_dist(internal_id):\n",
    "    return {0: 'uniform', 1: 'exponential'}[int(internal_id)]\n",
    "\n",
    "def round_to_nearest_pow_10(num):\n",
    "    next_smallest = 10**math.floor(math.log10(num))\n",
    "    return next_smallest * math.ceil(float(num) / float(next_smallest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c516a9-5e85-44a8-ad87-1541551cfa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_func_key = \"raw_func_name\"\n",
    "# func_key = \"func_name\"\n",
    "dataset_key = \"dataset\"\n",
    "dataset_size_key = \"dataset_size\"\n",
    "rounded_dataset_size_key = \"rounded_dataset_size\"\n",
    "probing_dist_key = \"probing_dist\"\n",
    "dataset_order_key = \"ds_order\"\n",
    "ns_per_key = \"ns_per_key\"\n",
    "throughput_key = \"throughput\" \n",
    "order_key = \"order\"\n",
    "hashfn_bytes_key = \"hashfn_byte_size\"\n",
    "hashfn_bits_per_key = \"hashfn_bits_per_key\"\n",
    "sample_size_key = \"sample_size\"\n",
    "sample_n_key = \"sample_n\"\n",
    "\n",
    "build_time_key = \"build_time\"\n",
    "build_throughput_key = \"build_throughput\"\n",
    "sample_time_key = \"sample_time\"\n",
    "sample_throughput_key = \"sample_throughput\"\n",
    "shuffle_time_key = \"shuffle_time\"\n",
    "shuffle_throughput_key = \"shuffle_throughput\"\n",
    "sample_sort_time_key = \"samplesort_time\"\n",
    "sample_sort_throughput_key = \"sample_sort_throughput\"\n",
    "total_sample_time_key = \"total_sample_time\"\n",
    "totalsample_throughput_key = \"total_sample_throughput\"\n",
    "\n",
    "th_df = df[(df[\"name\"].str.startswith(\"BM_build_and_throughput\")) & (df[\"run_type\"] == \"aggregate\") & (df[\"aggregate_name\"] == \"median\")].copy(deep=True)\n",
    "th_df[raw_func_key] = th_df[\"label\"].apply(lambda x : x.split(\":\")[0])\n",
    "# th_df[func_key] = th_df[raw_func_key].apply(function_name)\n",
    "th_df[dataset_key] = th_df[\"label\"].apply(lambda x : dataset_name(x.split(\":\")[1]))\n",
    "th_df[rounded_dataset_size_key] = th_df[dataset_size_key].apply(round_to_nearest_pow_10)\n",
    "th_df[dataset_order_key] = th_df[dataset_key].apply(dataset_order)\n",
    "th_df[probing_dist_key] = th_df[\"name\"].apply(lambda x : probing_dist(x.split(\"/\")[4]))\n",
    "th_df[sample_size_key] = th_df[\"name\"].apply(lambda x : int(x.split(\"/\")[3]))\n",
    "empty_th_loop_overhead = th_df[th_df[raw_func_key].str.startswith(\"DoNothing\")].agg({\"cpu_time\": 'mean'}).values[0]\n",
    "th_df = th_df[~th_df[raw_func_key].str.startswith(\"DoNothing\")]\n",
    "th_df[ns_per_key] = th_df.apply(lambda x : x[\"cpu_time\"] - empty_th_loop_overhead, axis=1)\n",
    "th_df[throughput_key] = th_df[\"cpu_time\"].apply(lambda x : 10**9 / x)\n",
    "th_df[hashfn_bits_per_key] = th_df.apply(lambda x : x[hashfn_bytes_key] / x[dataset_size_key], axis=1)\n",
    "th_df[order_key] = th_df[raw_func_key].apply(do_order)\n",
    "th_df = th_df.sort_values(by=[order_key])\n",
    "\n",
    "sc_df = df[(df[\"name\"].str.startswith(\"BM_scattering\"))].copy(deep=True)\n",
    "sc_df[raw_func_key] = sc_df[\"label\"].apply(lambda x : x.split(\":\")[0])\n",
    "sc_df[sample_size_key] = sc_df[\"name\"].apply(lambda x : int(x.split(\"/\")[3]))\n",
    "sc_df[order_key] = sc_df[raw_func_key].apply(do_order)\n",
    "sc_df[dataset_key] = sc_df[\"label\"].apply(lambda x : dataset_name(x.split(\":\")[1]))\n",
    "sc_df[dataset_order_key] = sc_df[dataset_key].apply(dataset_order)\n",
    "sc_df[[raw_func_key, sample_size_key, dataset_key]][0:16]\n",
    "\n",
    "th_df[sample_n_key] = th_df.apply(lambda x: x[dataset_size_key] * (float(x[sample_size_key]) / 100.0), axis=1)\n",
    "th_df[build_time_key] = th_df.apply(lambda x : x[build_time_key] / x[sample_n_key], axis=1)\n",
    "th_df[build_throughput_key] = th_df[build_time_key].apply(lambda x : 1.0 / x)\n",
    "th_df[sample_sort_time_key] = th_df.apply(lambda x : x[sample_sort_time_key] / x[sample_n_key], axis=1)\n",
    "th_df[sample_sort_throughput_key] = th_df[sample_sort_time_key].apply(lambda x : 1.0 / x)\n",
    "th_df[sample_time_key] = th_df.apply(lambda x : x[sample_time_key] / x[sample_n_key], axis=1)\n",
    "th_df[sample_throughput_key] = th_df[sample_time_key].apply(lambda x : 1.0 / x)\n",
    "th_df[shuffle_time_key] = th_df.apply(lambda x : x[shuffle_time_key] / x[dataset_size_key], axis=1)\n",
    "th_df[shuffle_throughput_key] = th_df[shuffle_time_key].apply(lambda x : 1.0 / x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f1ebc33-335a-453a-83a8-7960a80e4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_throughput_deterioration(data, title, sample_size, off=(0.5, 0.03), onlyplot=None):\n",
    "    dists = set(data[probing_dist_key])\n",
    "    \n",
    "    rows = 8\n",
    "    cols = len(dists)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(fig_width*0.8, rows*fig_height*0.65), sharex=True, sharey=True)\n",
    "\n",
    "    data = data[data[sample_size_key] == sample_size].sort_values(by=[dataset_order_key, rounded_dataset_size_key])\n",
    "    for i, (dataset, df) in enumerate(data.groupby([dataset_key], sort=False)):\n",
    "        pad = 7.5\n",
    "        axs[i][-1].annotate(\n",
    "            dataset, \n",
    "            xy=(0, 0.5),\n",
    "            xytext=(125 + axs[i][-1].yaxis.labelpad + pad, 0),\n",
    "            xycoords=axs[i][-1].yaxis.label, \n",
    "            textcoords='offset points',\n",
    "            size='large', \n",
    "            ha='left', \n",
    "            va='center',\n",
    "            rotation=0\n",
    "        )\n",
    "        for j, (probing_dist, df) in enumerate(df.groupby([probing_dist_key], sort=False)):            \n",
    "            ax = axs[i][j]\n",
    "\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_ylim([10**6, 7*10**7])\n",
    "            # ax.set_xticks([10**i for i in [4, 5, 6, 7, 8, 9]])\n",
    "            if i == rows - 1:\n",
    "                ax.set_xlabel(\"dataset size\")\n",
    "            ax.grid(linestyle=\"--\", axis=\"both\")\n",
    "    \n",
    "            for k, (raw_name, df) in enumerate(df.groupby([raw_func_key], sort=False)):\n",
    "                if onlyplot != None and raw_name not in onlyplot:\n",
    "                    continue\n",
    "                ax.plot(dataset_size_key, throughput_key, data=df, color=get_color(raw_name), label=function_name(raw_name), linewidth=1.5, marker='.')\n",
    "                \n",
    "            if i == 0:\n",
    "                # ax.set_ylabel(\"normalized entries per slot\")\n",
    "                ax.annotate(probing_dist, \n",
    "                            xy=(0.5, 1), \n",
    "                            xytext=(0, pad), \n",
    "                            xycoords='axes fraction', \n",
    "                            textcoords='offset points', \n",
    "                            size='large', \n",
    "                            ha='center', \n",
    "                            va='baseline',\n",
    "                           )\n",
    "\n",
    "    h, l = axs[0][0].get_legend_handles_labels()\n",
    "    legend = fig.legend(h, l, \n",
    "               loc='lower center',\n",
    "               bbox_to_anchor=off,\n",
    "               ncol=3,\n",
    "               borderpad=0.4, \n",
    "               labelspacing=0.2, \n",
    "               handlelength=1.0, \n",
    "               handletextpad=0.5, \n",
    "               columnspacing=0.7\n",
    "              )\n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(3.0)\n",
    "                \n",
    "    # overall title\n",
    "    fig.suptitle(f\"{title} Throughput (items per second), {sample_size}% sample\", y=0.935, fontweight=\"bold\")\n",
    "    fig.text(0.02, 0.5, 'hashed items per second', va='center', rotation='vertical')\n",
    "    \n",
    "    fig.savefig(f\"throughput_deterioration_{title.casefold()}_sample_{sample_size}.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    fig.savefig(f\"throughput_deterioration_{title.casefold()}_sample_{sample_size}.pgf\", bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "reset_colors()\n",
    "for sample_size in [1, 100]:\n",
    "    plot_throughput_deterioration(th_df, \"Splines\", sample_size=sample_size, off=(0.5, 0.0), onlyplot=[\n",
    "        'pgm_hash_eps128_epsrec128',\n",
    "        'pgm_hash_eps16_epsrec16',\n",
    "        'pgm_hash_eps4_epsrec4',\n",
    "        'radix_spline_err128_rbits18',\n",
    "        'radix_spline_err16_rbits18',\n",
    "        'radix_spline_err4_rbits18',\n",
    "        'trie_spline_err128',\n",
    "        'trie_spline_err16',\n",
    "        'trie_spline_err4'\n",
    "    ])\n",
    "    plot_throughput_deterioration(th_df, \"RMI\", sample_size=sample_size, onlyplot=[\"rmi_hash_1000000\", \"rmi_hash_10000\", \"rmi_hash_100\"])\n",
    "    plot_throughput_deterioration(th_df, \"CHT\", sample_size=sample_size, onlyplot=['cht_64_128', 'cht_64_16', 'cht_64_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8880f70c-6374-4008-bc2e-272902aae179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_throughput(data, sample):\n",
    "    dists = set(data[probing_dist_key])\n",
    "    \n",
    "    rows = 8\n",
    "    cols = len(dists)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(fig_width*0.8, rows*fig_height*0.5), sharex=True, sharey=True)\n",
    "\n",
    "    data = data[(data[dataset_size_key] > 10**7) & (data[sample_size_key] == sample)].copy(deep=True).sort_values(by=[dataset_order_key, order_key])\n",
    "    for i, (dataset, df) in enumerate(data.groupby([dataset_key], sort=False)):\n",
    "        pad = 7.5\n",
    "        axs[i][-1].annotate(\n",
    "            dataset, \n",
    "            xy=(0, 0.5),\n",
    "            xytext=(125 + axs[i][-1].yaxis.labelpad + pad, 0),\n",
    "            xycoords=axs[i][-1].yaxis.label, \n",
    "            textcoords='offset points',\n",
    "            size='large', \n",
    "            ha='left', \n",
    "            va='center',\n",
    "            rotation=0\n",
    "        )\n",
    "        for j, (probing_dist, df) in enumerate(df.groupby([probing_dist_key], sort=False)):            \n",
    "            ax = axs[i][j]\n",
    "    \n",
    "            for k, (name, df) in enumerate(df.groupby([raw_func_key], sort=False)):\n",
    "                # print(name, df[throughput_key])\n",
    "                ax.bar(data=df, x=order_key, height=throughput_key, label=function_name(name), color=get_color(name))\n",
    "\n",
    "            ax.tick_params(\n",
    "                axis='x',\n",
    "                which='both',\n",
    "                top=False, \n",
    "                bottom=False, \n",
    "                labelbottom=False\n",
    "            )\n",
    "\n",
    "            if i > 0:\n",
    "                ax.yaxis.offsetText.set_visible(False)\n",
    "            ax.grid(linestyle=\"--\", axis=\"y\", which=\"major\")\n",
    "    \n",
    "            if i == 0:\n",
    "                ax.annotate(\n",
    "                    probing_dist, \n",
    "                    xy=(0.5, 1), \n",
    "                    xytext=(0, pad), \n",
    "                    xycoords='axes fraction', \n",
    "                    textcoords='offset points', \n",
    "                    size='large', \n",
    "                    ha='center', \n",
    "                    va='baseline',\n",
    "                )\n",
    "\n",
    "    h, l = axs[0][0].get_legend_handles_labels()\n",
    "    legend = fig.legend(h, l, \n",
    "               loc='lower center',\n",
    "               bbox_to_anchor=(0.6, 0.0),\n",
    "               ncol=5,\n",
    "               borderpad=0.4, \n",
    "               labelspacing=0.2, \n",
    "               handlelength=1.0, \n",
    "               handletextpad=0.5, \n",
    "               columnspacing=0.7\n",
    "              )\n",
    "    \n",
    "    # overall title\n",
    "    fig.suptitle(f\"Throughput (full datasets), {sample}% sample\", y=0.94, fontweight=\"bold\")\n",
    "    fig.text(0.04, 0.5, 'hashed items per second', va='center', rotation='vertical')\n",
    "    \n",
    "    fig.savefig(f\"throughput_{sample}.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    fig.savefig(f\"throughput_{sample}.pgf\", bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plot_throughput(th_df, sample=1)\n",
    "plot_throughput(th_df, sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d75fbf5-2314-4117-ab0d-33344fa177f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatters(data, title, sample_size, only_plot=None):\n",
    "    rows = 2\n",
    "    cols = 4\n",
    "    \n",
    "    data = data[data[sample_size_key] == sample_size].copy(deep=True).sort_values(by=[dataset_order_key, order_key])\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(fig_width*0.8, rows*fig_height*0.7), sharex=True, sharey=True)\n",
    "    for i, (dataset, df) in enumerate(data.groupby([dataset_key], sort=False)):\n",
    "        ax = axs[int(i / cols)][i % cols]\n",
    "        ax.set_title(dataset, pad=2.5)\n",
    "        if sample_size == 1:\n",
    "            ax.set_ylim([0.75, 1.25])\n",
    "        else:\n",
    "            ax.set_ylim([0.985, 1.015])\n",
    "        if int(i/cols) == rows - 1:\n",
    "            ax.set_xlabel(\"bucket (0 to 100)\")\n",
    "\n",
    "        for _, baseline in df.iterrows():\n",
    "            name = baseline[raw_func_key]\n",
    "            if only_plot != None and name not in only_plot:\n",
    "                continue\n",
    "                \n",
    "            bucket_cnt = 100\n",
    "            expected_per_bucket = float(baseline[dataset_size_key])/float(bucket_cnt)\n",
    "            normalized_scatters = [float(baseline[f\"bucket_{k}\"])/expected_per_bucket for k in range(bucket_cnt)]\n",
    "            ax.plot(np.arange(0, 100.0, 100.0 / bucket_cnt), normalized_scatters, color=get_color(get_color(name)), label=function_name(name), linewidth=1)\n",
    "    \n",
    "    h, l = axs[0][0].get_legend_handles_labels()\n",
    "    legend = fig.legend(h, l, \n",
    "        loc='upper left',\n",
    "        bbox_to_anchor=(0.9, 0.9),\n",
    "        ncol=1, \n",
    "        borderpad=0.4, \n",
    "        labelspacing=0.2, \n",
    "        handlelength=1.0, \n",
    "        handletextpad=0.5, \n",
    "        columnspacing=1.0\n",
    "    )\n",
    "    # for line in legend.get_lines():\n",
    "    #     line.set_linewidth(3.0)\n",
    "    \n",
    "    # overall title\n",
    "    fig.suptitle(f\"Learned Scattering ({title.capitalize()} models, {sample_size}% sample)\", y=1.02, fontweight=\"bold\")\n",
    "    fig.text(0.04, 0.5, 'normalized counts', va='center', rotation='vertical')\n",
    "    \n",
    "    fig.savefig(f\"scatter_{title}_{sample_size}.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    fig.savefig(f\"scatter_{title}_{sample_size}.pgf\", bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "for sample_size in [1, 100]:\n",
    "    plot_scatters(sc_df, \"large\", sample_size=sample_size, only_plot={\n",
    "     'cht_64_4',\n",
    "     'pgm_hash_eps4_epsrec4',\n",
    "     'radix_spline_err4_rbits18',\n",
    "     'rmi_hash_1000000',\n",
    "     'trie_spline_err4'\n",
    "    })\n",
    "    plot_scatters(sc_df, \"medium\", sample_size=sample_size, only_plot={\n",
    "     'cht_64_16',\n",
    "     'pgm_hash_eps16_epsrec16',\n",
    "     'radix_spline_err16_rbits18',\n",
    "     'rmi_hash_10000',\n",
    "     'trie_spline_err16',\n",
    "    })\n",
    "    plot_scatters(sc_df, \"small\", sample_size=sample_size, only_plot={\n",
    "     'cht_64_128',\n",
    "     'pgm_hash_eps128_epsrec128',\n",
    "     'radix_spline_err128_rbits18',\n",
    "     'rmi_hash_100',\n",
    "     'trie_spline_err128',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2336100-97a0-4112-bf38-1e7366353de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_build_time(data, title, key):\n",
    "    rows = 8\n",
    "    cols = 2\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(fig_width*0.8, rows*fig_height*0.6), sharex=True, sharey=True)\n",
    "\n",
    "    data = data[(data[rounded_dataset_size_key] >= 10**8) & (data[raw_func_key] != \"cht_64_4\") & (data[probing_dist_key] == 'uniform')].copy(deep=True).sort_values(by=[dataset_order_key, order_key])\n",
    "    for i, (dataset, df) in enumerate(data.groupby([dataset_key], sort=False)):\n",
    "        pad = 7.5\n",
    "        axs[i][-1].annotate(\n",
    "            dataset, \n",
    "            xy=(0, 0.5),\n",
    "            xytext=(125 + axs[i][-1].yaxis.labelpad + pad, 0),\n",
    "            xycoords=axs[i][-1].yaxis.label, \n",
    "            textcoords='offset points',\n",
    "            size='large', \n",
    "            ha='left', \n",
    "            va='center',\n",
    "            rotation=0\n",
    "        )\n",
    "        \n",
    "        for j, (sample_size, df) in enumerate(df.groupby([sample_size_key], sort=False)):            \n",
    "            ax = axs[i][j]\n",
    "\n",
    "            ax.set_yticks([i * 10**8 for i in [0, 2.5, 5, 7.5]])\n",
    "            # ax.set_ylim([5 * 10**4, 2 * 10**9])\n",
    "            ax.grid(linestyle=\"--\", axis=\"y\", which=\"major\")\n",
    "\n",
    "            if i > 0:\n",
    "                ax.yaxis.offsetText.set_visible(False)\n",
    "    \n",
    "            for raw_name, df in df.groupby([raw_func_key], sort=False):\n",
    "                ax.bar(data=df, x=df[order_key].values[0], height=key, label=function_name(raw_name), color=get_color(raw_name))\n",
    "                \n",
    "            if i == 0:\n",
    "                ax.annotate(\n",
    "                    f\"{sample_size}% sample\", \n",
    "                    xy=(0.5, 1), \n",
    "                    xytext=(0, pad), \n",
    "                    xycoords='axes fraction', \n",
    "                    textcoords='offset points', \n",
    "                    size='large', \n",
    "                    ha='center', \n",
    "                    va='baseline',\n",
    "                )\n",
    "                \n",
    "            ax.tick_params(\n",
    "                axis='x',\n",
    "                which='both',\n",
    "                top=False, \n",
    "                bottom=False, \n",
    "                labelbottom=False\n",
    "            )\n",
    "\n",
    "    h, l = axs[0][0].get_legend_handles_labels()\n",
    "    legend = fig.legend(h, l, \n",
    "               loc='lower center',\n",
    "               bbox_to_anchor=(0.6, 0.02),\n",
    "               ncol=5,\n",
    "               borderpad=0.4, \n",
    "               labelspacing=0.2, \n",
    "               handlelength=1.0, \n",
    "               handletextpad=0.5, \n",
    "               columnspacing=0.7\n",
    "              )\n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(3.0)\n",
    "                \n",
    "    # overall title\n",
    "    fig.suptitle(f\"{title.capitalize()} throughput (full datasets)\", y=0.94, fontweight=\"bold\")\n",
    "    fig.text(0.04, 0.5, 'ingested items per second', va='center', rotation='vertical')\n",
    "    \n",
    "    fig.savefig(f\"build.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    fig.savefig(f\"build.pgf\", bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plot_build_time(th_df, \"build\", build_throughput_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e24871b-053b-447b-88f3-7d521d2d65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_build_overhead(data):\n",
    "    data = data[[rounded_dataset_size_key, sample_size_key, shuffle_throughput_key, sample_throughput_key, sample_sort_throughput_key]]\\\n",
    "        .sort_values(by=[rounded_dataset_size_key, sample_size_key])\\\n",
    "        .groupby(by=[rounded_dataset_size_key, sample_size_key], sort=False, as_index=False)\\\n",
    "        .median()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(fig_width*0.8, fig_height))\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    \n",
    "    ax.plot(rounded_dataset_size_key, shuffle_throughput_key, data=data, label=\"Shuffle\", linewidth=1.5, marker='.')\n",
    "    for sample_size in [1, 100]:\n",
    "        df = data[data[sample_size_key] == sample_size]\n",
    "        ax.plot(rounded_dataset_size_key, sample_throughput_key, data=df, label=f\"Copy ({sample_size}%)\", linewidth=1.5, marker='.')\n",
    "    for sample_size in [1, 100]:\n",
    "        df = data[data[sample_size_key] == sample_size]\n",
    "        ax.plot(rounded_dataset_size_key, sample_sort_throughput_key, data=df, label=f\"Sort ({sample_size}%)\", linewidth=1.5, marker='.')\n",
    "\n",
    "    \n",
    "    fig.legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0.9, 0.9),\n",
    "        ncol=1,\n",
    "        borderpad=0.4, \n",
    "        labelspacing=0.2, \n",
    "        handlelength=1.0, \n",
    "        handletextpad=0.5, \n",
    "        columnspacing=0.7\n",
    "    )\n",
    "    \n",
    "    ax.grid(linestyle=\"-\", axis=\"both\", which=\"major\", color=\"#888\")\n",
    "    ax.grid(linestyle=\"--\", axis=\"both\", which=\"minor\", color=\"#DDD\")\n",
    "    \n",
    "    ax.set_xlabel(\"Dataset Size\")\n",
    "    ax.set_ylabel(\"Items per second\")\n",
    "    \n",
    "    fig.suptitle(f\"Throughput of Static Build Overhead\", y=1.0, fontweight=\"bold\")\n",
    "        \n",
    "    fig.savefig(f\"build_overhead.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    fig.savefig(f\"build_overhead.pgf\", bbox_inches=\"tight\", dpi=300)\n",
    "    \n",
    "plot_build_overhead(th_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc1fee8-6733-4bef-b6af-9c5d9724da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_space_vs_time(data, sample_size=100, title=None, xlim=None, ymax=None, xticks=None, yticks=None):\n",
    "    dists = set(data[probing_dist_key])\n",
    "    \n",
    "    rows = 8\n",
    "    cols = len(dists)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(fig_width*0.8, rows*fig_height*0.5), sharex=True, sharey=True)\n",
    "\n",
    "    data = data[(data[rounded_dataset_size_key] >= 10**8) & (data[sample_size_key] == sample_size)].copy(deep=True).sort_values(by=[dataset_order_key, order_key])\n",
    "    for i, (dataset, df) in enumerate(data.groupby([dataset_key], sort=False)):\n",
    "        pad = 7.5\n",
    "        axs[i][-1].annotate(\n",
    "            dataset, \n",
    "            xy=(0, 0.5),\n",
    "            xytext=(125 + axs[i][-1].yaxis.labelpad + pad, 0),\n",
    "            xycoords=axs[i][-1].yaxis.label, \n",
    "            textcoords='offset points',\n",
    "            size='large', \n",
    "            ha='left', \n",
    "            va='center',\n",
    "            rotation=0\n",
    "        )\n",
    "        \n",
    "        for j, (probing_dist, df) in enumerate(df.groupby([probing_dist_key], sort=False)):            \n",
    "            ax = axs[i][j]\n",
    "    \n",
    "            for raw_name, df in df.groupby([raw_func_key], sort=False):\n",
    "                ax.scatter(x=df[hashfn_bits_per_key], y=df[\"cpu_time\"], label=function_name(raw_name), color=get_color(raw_name), marker=get_marker(raw_name), s=20 if raw_name == \"rmi_hash_100\" else 14)\n",
    "\n",
    "            if xlim != None:\n",
    "                ax.set_xlim(xlim)\n",
    "            if ymax != None:\n",
    "                ax.set_ylim([0, ymax])\n",
    "            if xticks != None:\n",
    "                ax.set_xticks(xticks)\n",
    "            if yticks != None:\n",
    "                ax.set_yticks(yticks)\n",
    "\n",
    "            ax.grid(linestyle=\"--\", axis=\"both\")\n",
    "            ax.set_xlabel(\"bits per key\")\n",
    "    \n",
    "            if i == 0:\n",
    "                ax.annotate(\n",
    "                    probing_dist, \n",
    "                    xy=(0.5, 1), \n",
    "                    xytext=(0, pad), \n",
    "                    xycoords='axes fraction', \n",
    "                    textcoords='offset points', \n",
    "                    size='large', \n",
    "                    ha='center', \n",
    "                    va='baseline',\n",
    "                )\n",
    "\n",
    "    h, l = axs[0][0].get_legend_handles_labels()\n",
    "    legend = fig.legend(h, l, \n",
    "               loc='lower center',\n",
    "               bbox_to_anchor=(0.6, -0.04),\n",
    "               ncol=5,\n",
    "               borderpad=0.4, \n",
    "               labelspacing=0.2, \n",
    "               handlelength=1.0, \n",
    "               handletextpad=0.5, \n",
    "               columnspacing=0.7\n",
    "              )\n",
    "    \n",
    "    # overall title\n",
    "    fig.suptitle(f\"{f'{title.capitalize()} ' if title != None else ''} Space vs. Latency (full datasets, {sample_size}% sample)\", y=0.94, fontweight=\"bold\")\n",
    "    fig.text(0.03, 0.5, 'nanoseconds per key', va='center', rotation='vertical')\n",
    "    \n",
    "    fig.savefig(f\"pareto{f'_{title}' if title != None else ''}_{sample_size}.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    fig.savefig(f\"pareto{f'_{title}' if title != None else ''}_{sample_size}.pgf\", bbox_inches=\"tight\", dpi=300)\n",
    "    return\n",
    "\n",
    "plot_space_vs_time(th_df, sample_size=100, xticks=[0, 1, 2, 3, 4, 5, 6, 7], yticks=[0, 250, 500, 750])\n",
    "plot_space_vs_time(th_df, sample_size=100, title=\"zoomed\", xlim=[-0.02, 0.5], ymax=200, yticks=[0, 50, 100, 150, 200])\n",
    "plot_space_vs_time(th_df, sample_size=1, yticks=[0, 50, 100, 150])\n",
    "plot_space_vs_time(th_df, sample_size=1, title=\"zoomed\", xlim=[-0.001, 0.025], ymax=75, yticks=[0, 25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c730e-5c6d-4166-bd9d-cee6b7a3c0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
